{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbKVs9eK5c5Y"
      },
      "source": [
        "Pole extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SeGk1564JmIh",
        "outputId": "6b764e1e-e171-43fa-c2e0-6ca7c48c83fb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_and_save_poles(image_path, label_path, free_pole_dir, non_free_pole_dir, display_results=False):\n",
        "    \"\"\"\n",
        "    Processes a single image and its label file, extracting poles from cells\n",
        "    of class 0 and 2, saves them, and optionally displays the results.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read image at {image_path}. Skipping.\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            print(f\"Warning: Label file not found for {image_path}. Skipping.\")\n",
        "            return\n",
        "\n",
        "        img_h, img_w, _ = img.shape\n",
        "\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Process each labeled cell in the file\n",
        "        for i, line in enumerate(lines):\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "\n",
        "            class_id = int(parts[0])\n",
        "\n",
        "            # Only process class 0 (free poles) and class 2 (non-free poles)\n",
        "            if class_id not in [0, 2]:\n",
        "                continue\n",
        "\n",
        "            # Determine the correct output directory based on the class ID\n",
        "            output_dir = free_pole_dir if class_id == 0 else non_free_pole_dir\n",
        "\n",
        "            # --- Denormalize Coordinates and Find Rotated Rectangle ---\n",
        "            coords = np.array([float(p) for p in parts[1:]]).reshape(-1, 2)\n",
        "            denormalized_points = (coords * np.array([img_w, img_h])).astype(np.float32)\n",
        "            rect = cv2.minAreaRect(denormalized_points)\n",
        "\n",
        "            # --- Straighten the Cell and Extract Poles ---\n",
        "            center, size, angle = rect\n",
        "            width, height = size\n",
        "\n",
        "            if width > height:\n",
        "                width, height = height, width\n",
        "                angle += 90\n",
        "\n",
        "            extension = 0 * height\n",
        "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "            rotated_img = cv2.warpAffine(img, M, (img_w, img_h))\n",
        "\n",
        "            crop_size = (int(width), int(height + 2 * extension))\n",
        "            super_crop = cv2.getRectSubPix(rotated_img, crop_size, center)\n",
        "\n",
        "            if super_crop is None or super_crop.size == 0:\n",
        "                print(f\"Warning: Failed to create a valid crop for cell {i} in {image_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # --- Slice the Straightened Crop to Get the Poles ---\n",
        "            mid_point_y = int(extension + height / 2)\n",
        "            pole1_img = super_crop[0:mid_point_y, :]\n",
        "            pole2_img = super_crop[mid_point_y:, :]\n",
        "\n",
        "            # --- Save the Extracted Poles ---\n",
        "            unique_id = uuid.uuid4().hex[:8]\n",
        "            base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "            pole1_filename = f\"{base_filename}_cell{i}_pole1_{unique_id}.png\"\n",
        "            pole2_filename = f\"{base_filename}_cell{i}_pole2_{unique_id}.png\"\n",
        "            pole1_save_path = os.path.join(output_dir, pole1_filename)\n",
        "            pole2_save_path = os.path.join(output_dir, pole2_filename)\n",
        "            cv2.imwrite(pole1_save_path, pole1_img)\n",
        "            cv2.imwrite(pole2_save_path, pole2_img)\n",
        "\n",
        "            # --- Display Results if Requested ---\n",
        "            if display_results:\n",
        "                print(f\"\\nDisplaying poles for cell {i} (Class {class_id}) from: {os.path.basename(image_path)}\")\n",
        "\n",
        "                # Create a copy of the original image to draw on\n",
        "                img_for_display = img.copy()\n",
        "\n",
        "                # --- Draw the original cell's bounding box for reference ---\n",
        "                # This box comes directly from the initial detection and should be correct.\n",
        "                cell_box_points = cv2.boxPoints(rect)\n",
        "                cv2.drawContours(img_for_display, [cell_box_points.astype(int)], 0, (0, 255, 0), 2) # Green\n",
        "\n",
        "                # --- Calculate pole bounding boxes on the original image ---\n",
        "                # This requires transforming the pole crop corners back to the original image space\n",
        "                M_inv = cv2.invertAffineTransform(M)\n",
        "                crop_w, crop_h = crop_size\n",
        "\n",
        "                # Top-left corner of the crop in the rotated image's coordinate system\n",
        "                top_left_in_rotated = np.array([center[0] - crop_w / 2, center[1] - crop_h / 2])\n",
        "\n",
        "                # Corners of pole 1 in the rotated image\n",
        "                p1_corners_rot = np.array([\n",
        "                    top_left_in_rotated,\n",
        "                    top_left_in_rotated + [width, 0],\n",
        "                    top_left_in_rotated + [width, mid_point_y],\n",
        "                    top_left_in_rotated + [0, mid_point_y]\n",
        "                ], dtype=np.float32)\n",
        "\n",
        "                # Corners of pole 2 in the rotated image\n",
        "                p2_corners_rot = np.array([\n",
        "                    top_left_in_rotated + [0, mid_point_y],\n",
        "                    top_left_in_rotated + [width, mid_point_y],\n",
        "                    top_left_in_rotated + [width, crop_h],\n",
        "                    top_left_in_rotated + [0, crop_h]\n",
        "                ], dtype=np.float32)\n",
        "\n",
        "                # Transform corners back to original image coordinates\n",
        "                p1_corners_orig = cv2.transform(p1_corners_rot.reshape(-1, 1, 2), M_inv).reshape(-1, 2)\n",
        "                p2_corners_orig = cv2.transform(p2_corners_rot.reshape(-1, 1, 2), M_inv).reshape(-1, 2)\n",
        "\n",
        "                # Draw the pole contours on the display image\n",
        "                cv2.drawContours(img_for_display, [p1_corners_orig.astype(int)], 0, (255, 0, 0), 2) # Blue\n",
        "                cv2.drawContours(img_for_display, [p2_corners_orig.astype(int)], 0, (0, 0, 255), 2) # Red\n",
        "\n",
        "                # --- Create and show the plot ---\n",
        "                fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "                axes[0].imshow(cv2.cvtColor(img_for_display, cv2.COLOR_BGR2RGB))\n",
        "                axes[0].set_title(\"Original with Pole Boxes\")\n",
        "                axes[0].axis('off')\n",
        "\n",
        "                axes[1].imshow(cv2.cvtColor(pole1_img, cv2.COLOR_BGR2RGB))\n",
        "                axes[1].set_title(\"Extracted Pole 1\")\n",
        "                axes[1].axis('off')\n",
        "\n",
        "                axes[2].imshow(cv2.cvtColor(pole2_img, cv2.COLOR_BGR2RGB))\n",
        "                axes[2].set_title(\"Extracted Pole 2\")\n",
        "                axes[2].axis('off')\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {image_path}: {e}\")\n",
        "\n",
        "\n",
        "def process_dataset(root_dir, free_pole_dir, non_free_pole_dir, display_results=False):\n",
        "    \"\"\"\n",
        "    Recursively finds all images in the dataset and processes them to extract poles.\n",
        "    \"\"\"\n",
        "    os.makedirs(free_pole_dir, exist_ok=True)\n",
        "    os.makedirs(non_free_pole_dir, exist_ok=True)\n",
        "    print(f\"Saving free poles to: {free_pole_dir}\")\n",
        "    print(f\"Saving non-free poles to: {non_free_pole_dir}\")\n",
        "\n",
        "    images_root = os.path.join(root_dir, 'images')\n",
        "\n",
        "    for dirpath, _, filenames in os.walk(images_root):\n",
        "        for filename in filenames:\n",
        "            if filename.lower().endswith('.png'):\n",
        "                image_path = os.path.join(dirpath, filename)\n",
        "                relative_path = os.path.relpath(image_path, images_root)\n",
        "                label_filename = os.path.splitext(relative_path)[0] + '.txt'\n",
        "                label_path = os.path.join(root_dir, 'labels', label_filename)\n",
        "\n",
        "                print(f\"Processing: {image_path}\")\n",
        "                extract_and_save_poles(image_path, label_path, free_pole_dir, non_free_pole_dir, display_results)\n",
        "\n",
        "    print(\"\\nDataset processing complete.\")\n",
        "\n",
        "\n",
        "# --- Main execution ---\n",
        "if __name__ == '__main__':\n",
        "    # --- PLEASE CONFIGURE THESE PATHS ---\n",
        "    DATASET_ROOT_DIRECTORY = \"/content/drive/MyDrive/Colab Notebooks/Data/EnhancedPNG\"\n",
        "    OUTPUT_DIRECTORY = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced\"\n",
        "\n",
        "    # --- TOGGLE DISPLAY ON/OFF ---\n",
        "    # Set to True to see the plots for each processed cell.\n",
        "    # Set to False to run without any pop-up windows (faster).\n",
        "    SHOW_PLOTS = True\n",
        "\n",
        "    FREE_POLES_OUTPUT_DIR = os.path.join(OUTPUT_DIRECTORY, \"free_poles\")\n",
        "    NON_FREE_POLES_OUTPUT_DIR = os.path.join(OUTPUT_DIRECTORY, \"non_free_poles\")\n",
        "\n",
        "    process_dataset(DATASET_ROOT_DIRECTORY, FREE_POLES_OUTPUT_DIR, NON_FREE_POLES_OUTPUT_DIR, display_results=SHOW_PLOTS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am_MTgq75lmN"
      },
      "source": [
        "Splitting of Extracted poles dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t21gYJyLM-WT",
        "outputId": "ae46e097-7084-43bb-a9bc-a64c7693c1fb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_dataset(root_dir, train_ratio=0.9):\n",
        "    \"\"\"\n",
        "    Splits the classification dataset into training and validation sets.\n",
        "\n",
        "    The expected initial directory structure is:\n",
        "    root_dir/\n",
        "    â”œâ”€â”€ free_poles/\n",
        "    â”‚   â”œâ”€â”€ img1.png\n",
        "    â”‚   â””â”€â”€ img2.png\n",
        "    â””â”€â”€ non_free_poles/\n",
        "        â”œâ”€â”€ img3.png\n",
        "        â””â”€â”€ img4.png\n",
        "\n",
        "    The final directory structure will be:\n",
        "    root_dir/\n",
        "    â”œâ”€â”€ train/\n",
        "    â”‚   â”œâ”€â”€ free_poles/\n",
        "    â”‚   â””â”€â”€ non_free_poles/\n",
        "    â””â”€â”€ val/\n",
        "        â”œâ”€â”€ free_poles/\n",
        "        â””â”€â”€ non_free_poles/\n",
        "\n",
        "    Args:\n",
        "        root_dir (str): The path to the directory containing the class folders.\n",
        "        train_ratio (float): The proportion of the dataset to allocate for training.\n",
        "    \"\"\"\n",
        "    print(f\"Starting dataset split in: {root_dir}\")\n",
        "    print(f\"Train ratio: {train_ratio}, Validation ratio: {1 - train_ratio}\")\n",
        "\n",
        "    # Define paths for the new train and val directories\n",
        "    train_dir = os.path.join(root_dir, 'train')\n",
        "    val_dir = os.path.join(root_dir, 'val')\n",
        "\n",
        "    # List the class directories (e.g., 'free_poles', 'non_free_poles')\n",
        "    class_dirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
        "\n",
        "    # Filter out 'train' and 'val' if the script is run multiple times\n",
        "    class_dirs = [d for d in class_dirs if d not in ['train', 'val']]\n",
        "\n",
        "    if not class_dirs:\n",
        "        print(\"Error: No class directories found. The script expects subdirectories named after each class.\")\n",
        "        return\n",
        "\n",
        "    # Process each class directory\n",
        "    for class_name in class_dirs:\n",
        "        print(f\"\\nProcessing class: {class_name}\")\n",
        "\n",
        "        # Define source and destination paths\n",
        "        source_class_dir = os.path.join(root_dir, class_name)\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        val_class_dir = os.path.join(val_dir, class_name)\n",
        "\n",
        "        # Create the new train/val subdirectories for the class\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "        # Get all image files from the source class directory\n",
        "        images = [f for f in os.listdir(source_class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        random.shuffle(images) # Shuffle for a random split\n",
        "\n",
        "        # Calculate the split index\n",
        "        split_index = int(len(images) * train_ratio)\n",
        "\n",
        "        # Split the list of images\n",
        "        train_images = images[:split_index]\n",
        "        val_images = images[split_index:]\n",
        "\n",
        "        # Move files to the new directories\n",
        "        for image in train_images:\n",
        "            shutil.move(os.path.join(source_class_dir, image), os.path.join(train_class_dir, image))\n",
        "\n",
        "        for image in val_images:\n",
        "            shutil.move(os.path.join(source_class_dir, image), os.path.join(val_class_dir, image))\n",
        "\n",
        "        print(f\"Moved {len(train_images)} images to train/{class_name}\")\n",
        "        print(f\"Moved {len(val_images)} images to val/{class_name}\")\n",
        "\n",
        "        # After moving all files, the original class folder will be empty and can be removed\n",
        "        try:\n",
        "            os.rmdir(source_class_dir)\n",
        "            print(f\"Removed empty source directory: {source_class_dir}\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing directory {source_class_dir}: {e}\")\n",
        "\n",
        "    print(\"\\nDataset splitting complete.\")\n",
        "\n",
        "\n",
        "# --- Main execution ---\n",
        "if __name__ == '__main__':\n",
        "    # Set this to the directory containing your 'free_poles' and 'non_free_poles' folders\n",
        "    DATASET_DIRECTORY = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced\"\n",
        "\n",
        "    # Call the function to split the dataset\n",
        "    split_dataset(DATASET_DIRECTORY, train_ratio=0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWGEZfiZ59_0"
      },
      "source": [
        "Writing data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsOl-lKYTEC9",
        "outputId": "9b7b9b9e-3166-483d-c311-8d934c56983e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def create_data_yaml(root_dir):\n",
        "    \"\"\"\n",
        "    Creates the data.yaml file required for YOLOv8 classification training,\n",
        "    assuming a train/val split has already been made.\n",
        "\n",
        "    The expected directory structure is:\n",
        "    root_dir/\n",
        "    â”œâ”€â”€ train/\n",
        "    â”‚   â”œâ”€â”€ free_poles/\n",
        "    â”‚   â””â”€â”€ non_free_poles/\n",
        "    â””â”€â”€ val/\n",
        "        â”œâ”€â”€ free_poles/\n",
        "        â””â”€â”€ non_free_poles/\n",
        "\n",
        "    Args:\n",
        "        root_dir (str): The path to the directory containing train/ and val/ folders.\n",
        "    \"\"\"\n",
        "    # Using an absolute path is generally more robust for YOLO training.\n",
        "    abs_root_dir = os.path.abspath(root_dir)\n",
        "\n",
        "    # Define the content for the YAML file.\n",
        "    # YOLO will look for 'train' and 'val' folders inside the 'path' directory.\n",
        "    yaml_content = f\"\"\"\n",
        "# The absolute path to the dataset's root directory\n",
        "path: {abs_root_dir}\n",
        "\n",
        "# Train/val directories relative to 'path'\n",
        "train: train\n",
        "val: val\n",
        "\n",
        "# Number of classes\n",
        "nc: 2\n",
        "\n",
        "# Class names\n",
        "names:\n",
        "  0: free_poles\n",
        "  1: non_free_poles\n",
        "\"\"\"\n",
        "    # Define the full path for the new file\n",
        "    yaml_path = os.path.join(abs_root_dir, 'data.yaml')\n",
        "\n",
        "    # Write the content to the file\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        # Using strip() to remove leading/trailing whitespace from the multiline string\n",
        "        f.write(yaml_content.strip())\n",
        "\n",
        "    print(f\"Successfully created data.yaml at: {yaml_path}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "if __name__ == '__main__':\n",
        "    # Set this to the root directory containing your 'train' and 'val' folders\n",
        "    DATASET_DIRECTORY = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced\"\n",
        "\n",
        "    # Call the function to create the file\n",
        "    create_data_yaml(DATASET_DIRECTORY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0w_YquB6Chi"
      },
      "source": [
        "Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22_C_1AYWoEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irv-SfRcXUP4",
        "outputId": "4eef6a06-2152-4916-8203-602649066c57"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 classification model (pretrained)\n",
        "model = YOLO('yolov8x-cls.pt')  # 'n' for nano, choose larger model for better accuracy: yolov8s-cls.pt, yolov8m-cls.pt, yolov8l-cls.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5J9rGXHRYTsF",
        "outputId": "d866b37f-d83b-4f43-db33-25655d07d733"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8x-cls.pt') # or yolov8n-cls.pt, etc.\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "   data='/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/',\n",
        "   epochs=100,\n",
        "   imgsz=64,\n",
        "   batch=32,\n",
        "   workers=4,\n",
        "   patience=10,\n",
        "   device=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8DDY1Xqjs7GY",
        "outputId": "886e81b6-73a2-487b-d650-406ae2c77146"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# --- 1. Load a powerful, but balanced, model ---\n",
        "# 'l' (Large) is a great choice for high accuracy without the extreme training time of 'x'.\n",
        "model = YOLO('yolov8l-cls.pt')\n",
        "\n",
        "# --- 2. Train the model with the best combination of settings ---\n",
        "results = model.train(\n",
        "   # --- Dataset Configuration ---\n",
        "   data='/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced',\n",
        "\n",
        "   # --- Core Training Parameters ---\n",
        "   epochs=100,         # Train for 100 full cycles through the dataset\n",
        "   imgsz=64,           # Standardize input image size\n",
        "   batch=32,           # Process 32 images at a time (adjust if you get memory errors)\n",
        "   patience=20,        # Stop training early if validation accuracy doesn't improve for 20 epochs\n",
        "\n",
        "   # --- Data Augmentation for Better Generalization ---\n",
        "   degrees=90,         # Random rotations (-90 to +90 degrees)\n",
        "   fliplr=0.5,         # 50% chance to flip images horizontally\n",
        "   flipud=0.5,         # 50% chance to flip images vertically\n",
        "   scale=0.15,         # Randomly zoom in or out by up to 15%\n",
        "   hsv_h=0.015,        # Adjust color hue\n",
        "   hsv_s=0.7,          # Adjust color saturation\n",
        "   hsv_v=0.4,          # Adjust color brightness/value\n",
        "   mixup=0.1           # Mix images and labels together to create new training examples\n",
        ")\n",
        "\n",
        "# After training, you can find your best model in the 'runs/classify/trainX/weights/best.pt' directory\n",
        "print(\"\\nTraining complete! Your best model is saved and ready for the inference pipeline.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knUJoC6aA94M"
      },
      "source": [
        "Metrics evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_UPsWgd8N24",
        "outputId": "9c62d3cc-e166-467d-f4e1-e9bf1fd9d63a"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"runs/classify/train2/weights/best.pt\")\n",
        "metrics = model.val(data=\"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles\")\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "_VHWICv19Ztp",
        "outputId": "064a6d2b-0576-49c9-84cb-9b07260cfd28"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load the model and validate (cached results if already validated)\n",
        "model = YOLO(\"runs/classify/train2/weights/best.pt\")\n",
        "results = model.val(data=\"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles\")\n",
        "\n",
        "# Extract confusion matrix as numpy array\n",
        "cm = results.confusion_matrix.matrix\n",
        "\n",
        "# Define class names (replace with your actual class names)\n",
        "class_names = [\"free_poles\", \"Non_free_poles\"]\n",
        "\n",
        "# If you want integers (counts):\n",
        "cm_counts = np.rint(cm).astype(int)\n",
        "\n",
        "# Plot confusion matrix with counts\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_counts, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix (Counts)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4F5qHfQBolY"
      },
      "source": [
        "Confidence scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSFLLcPjBqyw",
        "outputId": "d6e6b643-c9b0-4e66-fab7-96e070fb0e77"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Load Model\n",
        "# -------------------------------------------------------------\n",
        "best_pt   = '/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/runs/classify/train2/weights/best.pt'\n",
        "cls_model = YOLO(best_pt, task='classify')\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Predict Helper\n",
        "# -------------------------------------------------------------\n",
        "def predict_with_probs(image_path: str):\n",
        "    \"\"\"\n",
        "    Returns: (predicted_class, confidence)\n",
        "    \"\"\"\n",
        "    results = cls_model.predict(\n",
        "        source=image_path,\n",
        "        task='classify',\n",
        "        imgsz=64,\n",
        "        verbose=False\n",
        "    )\n",
        "    probs = results[0].probs.data.tolist()\n",
        "    top1 = results[0].probs.top1\n",
        "    return top1, probs[top1]\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Numerical Evaluation Only\n",
        "# -------------------------------------------------------------\n",
        "def evaluate_folder(folder_path: str, true_class: int):\n",
        "    all_files = sorted([\n",
        "        os.path.join(folder_path, f)\n",
        "        for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif'))\n",
        "    ])\n",
        "\n",
        "    total = len(all_files)\n",
        "    correct = 0\n",
        "    wrong = 0\n",
        "\n",
        "    correct_confs = []\n",
        "    wrong_confs = []\n",
        "    all_confs = []\n",
        "\n",
        "    print(f\"\\nEvaluating: {folder_path}\")\n",
        "    print(f\"True class = {true_class} ({cls_model.names[true_class]})\")\n",
        "    print(f\"Total images = {total}\")\n",
        "\n",
        "    for img in all_files:\n",
        "        pred, prob = predict_with_probs(img)\n",
        "        all_confs.append(prob)\n",
        "\n",
        "        if pred == true_class:\n",
        "            correct += 1\n",
        "            correct_confs.append(prob)\n",
        "        else:\n",
        "            wrong += 1\n",
        "            wrong_confs.append(prob)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Numerical Summary\n",
        "    # -------------------------------\n",
        "    print(\"\\nðŸ“Œ NUMERICAL SUMMARY\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"Total Images        :\", total)\n",
        "    print(\"Correct Predictions :\", correct)\n",
        "    print(\"Wrong Predictions   :\", wrong)\n",
        "    print(f\"Accuracy            : {correct/total:.4f}\")\n",
        "\n",
        "    if wrong > 0:\n",
        "        avg_wrong_conf = sum(wrong_confs) / wrong\n",
        "        print(f\"Avg Confidence (Wrong Predictions)  : {avg_wrong_conf:.4f}\")\n",
        "    else:\n",
        "        print(\"Avg Confidence (Wrong Predictions)  : N/A\")\n",
        "\n",
        "    if correct > 0:\n",
        "        avg_correct_conf = sum(correct_confs) / correct\n",
        "        print(f\"Avg Confidence (Correct Predictions): {avg_correct_conf:.4f}\")\n",
        "    else:\n",
        "        print(\"Avg Confidence (Correct Predictions): N/A\")\n",
        "\n",
        "    avg_conf_all = sum(all_confs) / total\n",
        "    print(f\"Avg Confidence (All Predictions)    : {avg_conf_all:.4f}\")\n",
        "\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    return {\n",
        "        \"total\": total,\n",
        "        \"correct\": correct,\n",
        "        \"wrong\": wrong,\n",
        "        \"avg_conf_wrong\": (sum(wrong_confs)/wrong) if wrong>0 else None,\n",
        "        \"avg_conf_correct\": (sum(correct_confs)/correct) if correct>0 else None,\n",
        "        \"avg_conf_all\": avg_conf_all\n",
        "    }\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# RUN\n",
        "# -------------------------------------------------------------\n",
        "folder = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/train/free_poles\"\n",
        "true_class = 0  # Free pole\n",
        "\n",
        "evaluate_folder(folder, true_class)\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/train/non_free_poles\"\n",
        "true_class = 1  # Non Free pole\n",
        "\n",
        "evaluate_folder(folder, true_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MxPIV-86Cg4Y",
        "outputId": "3d2286b8-38d9-45fd-cbb1-83b0aa248fe1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Load Model\n",
        "# -------------------------------------------------------------\n",
        "best_pt   = '/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/runs/classify/train2/weights/best.pt'\n",
        "cls_model = YOLO(best_pt, task='classify')\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Predict Helper\n",
        "# -------------------------------------------------------------\n",
        "def predict_with_probs(image_path: str):\n",
        "    results = cls_model.predict(\n",
        "        source=image_path,\n",
        "        task='classify',\n",
        "        imgsz=64,\n",
        "        verbose=False\n",
        "    )\n",
        "    probs = results[0].probs.data.tolist()\n",
        "    top1 = results[0].probs.top1\n",
        "    return top1, probs[top1]\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Full Evaluation + Plotting\n",
        "# -------------------------------------------------------------\n",
        "def evaluate_and_plot(folder_path: str, true_class: int):\n",
        "    all_files = sorted([\n",
        "        os.path.join(folder_path, f)\n",
        "        for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif'))\n",
        "    ])\n",
        "\n",
        "    total = len(all_files)\n",
        "    correct = 0\n",
        "    wrong = 0\n",
        "\n",
        "    correct_confs = []\n",
        "    wrong_confs = []\n",
        "\n",
        "    print(f\"\\nEvaluating: {folder_path}\")\n",
        "    print(f\"True class = {true_class} ({cls_model.names[true_class]})\")\n",
        "    print(f\"Total images = {total}\")\n",
        "\n",
        "    # ---------- Predict ----------\n",
        "    for img in all_files:\n",
        "        pred, prob = predict_with_probs(img)\n",
        "\n",
        "        if pred == true_class:\n",
        "            correct += 1\n",
        "            correct_confs.append(prob)\n",
        "        else:\n",
        "            wrong += 1\n",
        "            wrong_confs.append(prob)\n",
        "\n",
        "    # ---------- Summary ----------\n",
        "    print(\"\\nðŸ“Œ NUMERICAL SUMMARY\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"Total Images        :\", total)\n",
        "    print(\"Correct Predictions :\", correct)\n",
        "    print(\"Wrong Predictions   :\", wrong)\n",
        "    print(f\"Accuracy            : {correct/total:.4f}\")\n",
        "\n",
        "    if wrong > 0:\n",
        "        print(f\"Avg Confidence (Wrong Predictions)  : {sum(wrong_confs)/wrong:.4f}\")\n",
        "    else:\n",
        "        print(\"Avg Confidence (Wrong Predictions)  : N/A\")\n",
        "\n",
        "    if correct > 0:\n",
        "        print(f\"Avg Confidence (Correct Predictions): {sum(correct_confs)/correct:.4f}\")\n",
        "    else:\n",
        "        print(\"Avg Confidence (Correct Predictions): N/A\")\n",
        "\n",
        "    all_confs = correct_confs + wrong_confs\n",
        "    print(f\"Avg Confidence (All Predictions)    : {sum(all_confs)/total:.4f}\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # =======================================================\n",
        "    # ðŸ“Š PLOT 1: Correct Predictions Confidence Scores\n",
        "    # =======================================================\n",
        "    if len(correct_confs) > 0:\n",
        "        plt.figure(figsize=(8,4))\n",
        "        plt.scatter(range(len(correct_confs)), correct_confs, alpha=0.7)\n",
        "        plt.title(\"Confidence Scores of Correct Predictions\")\n",
        "        plt.xlabel(\"Image Index\")\n",
        "        plt.ylabel(\"Confidence\")\n",
        "        plt.ylim(0, 1.05)\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "        plt.show()\n",
        "\n",
        "    # =======================================================\n",
        "    # ðŸ“Š PLOT 2: Wrong Predictions Confidence Scores\n",
        "    # =======================================================\n",
        "    if len(wrong_confs) > 0:\n",
        "        plt.figure(figsize=(8,4))\n",
        "        plt.scatter(range(len(wrong_confs)), wrong_confs, color='red', alpha=0.7)\n",
        "        plt.title(\"Confidence Scores of Wrong Predictions\")\n",
        "        plt.xlabel(\"Image Index\")\n",
        "        plt.ylabel(\"Confidence\")\n",
        "        plt.ylim(0, 1.05)\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# RUN\n",
        "# -------------------------------------------------------------\n",
        "folder = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/train/free_poles\"\n",
        "true_class = 0  # free pole\n",
        "\n",
        "evaluate_and_plot(folder, true_class)\n",
        "\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Colab Notebooks/Half_Cell_Poles_enhanced/train/non_free_poles\"\n",
        "true_class = 1 # free pole\n",
        "\n",
        "evaluate_and_plot(folder, true_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2rq34QXBMe6"
      },
      "source": [
        "Inference on whole image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgGbKpg4BdkV"
      },
      "source": [
        "Ground Truth vs Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pPuHv-mBoSX"
      },
      "source": [
        "Analysis of 2-level Process"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
